{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "# Standard Libraries\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Numerical and Scientific Libraries\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import skew, kurtosis, jarque_bera, shapiro, anderson\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# Data Analysis and Visualization Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Interactive Data Visualization Libraries\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Other Libraries\n",
    "from tqdm import tqdm as tqdm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "\n",
    "##     ##               #######                                                                                                             \n",
    "##      ##              #     #                                                                                                             \n",
    "##       ##             #        #######  #######           #     #  #######  #######     #     #######  ######   #        #######  ####### \n",
    "##       ##             #######  #           #              #     #  #     #  #     #     #     #     #  #    #   #        #        #       \n",
    "##       ##                  ##  ####        #               #   #   #######  #######     #     #######  #######  #        ####     ####### \n",
    "##      ##              #    ##  #           #                # #    #     #  #    #      #     #     #  #     #  #        #              # \n",
    "##     ##               #######  #######     #                 #     #     #  #    ##     #     #     #  #######  #######  #######  #######\n",
    "\n",
    "\n",
    "# Define year range that should be incorporated\n",
    "time_start = 2001\n",
    "time_end = 2022\n",
    "\n",
    "# Asset classes that are included either directly or as risk/return proxy into German Retail Investor Portfolio\n",
    "retail_asset_classes = ['Listed Foreign Public Equity','Other Equity Instruments','State Bonds','Corporate Bonds','Listed Domestic Public Equity','Fixed Term and Savings Deposit','Public Investment Funds','Cash']\n",
    "asset_classes_ex1 = ['Listed Foreign Public Equity','Other Equity Instruments','State Bonds','Corporate Bonds','Listed Domestic Public Equity','Fixed Term and Savings Deposit','Public Investment Funds','Cash']\n",
    "\n",
    "# Define max weight per asset class for restricted portfolio optimization\n",
    "max_weight = 0.33\n",
    "\n",
    "# Define cash for restricted portfolio optimization\n",
    "cash_level = 0.428\n",
    "\n",
    "\n",
    "# Define number of shots per Monte Carlo Simulation\n",
    "n_unrestricted = 100\n",
    "n_restricted = 10000000\n",
    "\n",
    "# Define risk free rate for Sharpe calc.\n",
    "risk_free_rate=0.016 \n",
    "\n",
    "# Activate model\n",
    "active_classes = asset_classes_ex1.copy()\n",
    "\n",
    "\n",
    "\n",
    "#######   ##               ######                                                                           #######                                                                                  \n",
    "#######    ##              #                                                                                #     #                                                                                  \n",
    "     ##     ##             #        #     #  #     #  #######  #######     #     #######  #     #           #     #  #######  #######     #     #     #     #     #######     #     #######  #     # \n",
    "#######     ##             #####    #     #  ##    #  #           #        #     #     #  ##    #           ##    #  #        #           #     ##    #     #        #        #     #     #  ##    # \n",
    "##          ##             ##       #     #  # ### #  #           #        #     #     #  # ### #           ##    #  ####     ####        #     # ### #     #        #        #     #     #  # ### # \n",
    "#######    ##              ##       #     #  #    ##  #           #        #     #     #  #    ##           ##    #  #        #           #     #    ##     #        #        #     #     #  #    ## \n",
    "#######   ##               ##       #######  #     #  #######     #        #     #######  #     #           #######  #######  #           #     #     #     #        #        #     #######  #     # \n",
    "                                                                                                                                                                                                      \n",
    "\n",
    "# Calculate Bayes_Steins estimates using the shrikage factor w\n",
    "def bayes_stein_returns(matrix, adjust=True):\n",
    "\n",
    "    t, n = matrix.shape\n",
    "    sample_means = matrix.mean(axis=0)\n",
    "    ones = np.ones_like(sample_means)\n",
    "\n",
    "    E = np.cov(matrix, rowvar=False)\n",
    "    # Zellner & Chetty adjustment of sample cov matrix\n",
    "    adj_Z_C = (float(t) - 1) / (t - n - 2)\n",
    "    E *= round(adj_Z_C, 4) \n",
    "    I = np.linalg.inv(E)\n",
    "    grand_mean = sample_means.dot(I).dot(ones.T) / ones.dot(I).dot(ones.T)\n",
    "    diff = sample_means - grand_mean\n",
    "    denominator = n + 2 + diff.dot(t*I).dot(diff.T)\n",
    "    w = round((n + 2) / denominator, 4)\n",
    "    print('The weighting coefficient in Bayes-Stein shrinkage: {}'.format(w))\n",
    "    adjusted_means = (1 - w)*sample_means + w*grand_mean\n",
    "\n",
    "    return adjusted_means\n",
    "\n",
    "# Define a function to calculate CVaR at a given confidence level\n",
    "def calculate_cvar(data, alpha):\n",
    "    sorted_returns = np.sort(data)\n",
    "    var_index = int((1 - alpha) * len(sorted_returns))\n",
    "    cvar = -sorted_returns[:var_index].mean()\n",
    "    return cvar\n",
    "\n",
    "# Function to plot the simulated portfolios with the minimum variance port., highest sharpe port. and retail portfolio\n",
    "def plot_ef  (mean_variance_pairs,tickers_list,weights_list,risk_free_rate,retail_return,retail_std,title_name): \n",
    "    #-- Plot the risk vs. return of randomly generated portfolios\n",
    "    #-- Convert the list from before into an array for easy plotting\n",
    "    mean_variance_pairs = np.array(mean_variance_pairs)\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=mean_variance_pairs[:,1]**0.5, y=mean_variance_pairs[:,0], \n",
    "                        marker=dict(color=(mean_variance_pairs[:,0]-risk_free_rate)/(mean_variance_pairs[:,1]**0.5), \n",
    "                                    showscale=True, \n",
    "                                    size=7,\n",
    "                                    line=dict(width=1),\n",
    "                                    colorscale=\"RdBu\",\n",
    "                                    colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "                                    ), \n",
    "                        mode='markers',\n",
    "                        text=[str(np.array(tickers_list[i])) + \"<br>\" + str(np.array(weights_list[i]).round(2)) for i in range(len(tickers_list))]))\n",
    "    fig.update_layout(template='plotly_white',\n",
    "                    xaxis=dict(title='Annualised Risk (Volatility)'),\n",
    "                    yaxis=dict(title='Annualised Return'),\n",
    "                    title=title_name,\n",
    "                    width=1000,\n",
    "                    height=700,\n",
    "                    showlegend = False)\n",
    "\n",
    "    #-- Find the portfolio with the highest Sharpe ratio\n",
    "    sharpe_ratio = (mean_variance_pairs[:,0]-risk_free_rate) / (mean_variance_pairs[:,1]**0.5)\n",
    "    max_sharpe_idx = np.argmax(sharpe_ratio)\n",
    "    max_sharpe_weights = weights_list[max_sharpe_idx]\n",
    "    max_sharpe_tickers = tickers_list[max_sharpe_idx]\n",
    "    max_sharpe_return = np.round(mean_variance_pairs[max_sharpe_idx][0] * 100,decimals=2)\n",
    "    max_sharpe_risk = np.round(mean_variance_pairs[max_sharpe_idx][1]**0.5 * 100,decimals=2)\n",
    "\n",
    "    #-- Find the portfolio with the minimum variance\n",
    "    min_var_idx = np.argmin(mean_variance_pairs[:,1])\n",
    "    min_var_weights = weights_list[min_var_idx]\n",
    "    min_var_tickers = tickers_list[min_var_idx]\n",
    "    min_var_return = np.round(mean_variance_pairs[min_var_idx][0] * 100,decimals=2)\n",
    "    min_var_risk = np.round(mean_variance_pairs[min_var_idx][1]**0.5 * 100,decimals=2)\n",
    "\n",
    "\n",
    "    # Convert mean_variance_pairs_re into a NumPy array\n",
    "    mean_variance_pairs_array = np.array(mean_variance_pairs)\n",
    "\n",
    "    # Extract the standard deviation array\n",
    "    std_array = np.sqrt(mean_variance_pairs_array[:, 1])\n",
    "\n",
    "    # Find the index of the pair with the closest standard deviation\n",
    "    closest_index = np.argmin(np.abs(std_array - retail_std))\n",
    "\n",
    "    closest_std_tickers = tickers_list[closest_index]\n",
    "    closest_std_weights = weights_list[closest_index]\n",
    "\n",
    "    #-- Take the portfolio stats of the average German private houshold portfolio\n",
    "    # Extract the index as an array\n",
    "    retail_tickers = retail_asset_allocation.index.str.lower().to_numpy()\n",
    "    retail_weights = retail_asset_allocation['Allocation'].to_numpy()\n",
    "\n",
    "    #-- Add the portfolios to the scatter plot\n",
    "    fig.add_trace(go.Scatter(x=[mean_variance_pairs[max_sharpe_idx,1]**0.5], y=[mean_variance_pairs[max_sharpe_idx,0]], \n",
    "                            marker=dict(color='green', size=10), \n",
    "                            mode='markers', \n",
    "                            name=None,\n",
    "                            text=['Portfolio with highest Sharpe ratio (' + str(np.array(max_sharpe_tickers)) + ', ' + str(np.array(max_sharpe_weights).round(2)) + ')']))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[mean_variance_pairs[min_var_idx,1]**0.5], y=[mean_variance_pairs[min_var_idx,0]], \n",
    "                            marker=dict(color='red', size=10), \n",
    "                            mode='markers', \n",
    "                            name=None,\n",
    "                            text=['Minimum variance portfolio (' + str(np.array(min_var_tickers)) + ', ' + str(np.array(min_var_weights).round(2)) + ')']))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x = [retail_std], y= [retail_return], \n",
    "                            marker=dict(color='purple', size=10), \n",
    "                            mode='markers', \n",
    "                            name=None,\n",
    "                            text=['Retail Investor Portfolio (' + str(np.array(retail_tickers)) + ', ' + str(np.array(retail_weights).round(2)) + ')']))\n",
    "\n",
    "\n",
    "    #-- Add the efficient frontier line from the risk-free rate to the portfolio with the highest Sharpe ratio\n",
    "    ef_line_x = np.linspace(0, max(mean_variance_pairs[:,1]**0.5), 100)\n",
    "    ef_line_y = ef_line_x * sharpe_ratio[max_sharpe_idx] + risk_free_rate\n",
    "    fig.add_trace(go.Scatter(x=ef_line_x, y=ef_line_y, \n",
    "                            line=dict(color='black', width=2, dash='dash'),\n",
    "                            name='Efficient Frontier'))\n",
    "\n",
    "\n",
    "    # Plot the three relevant highlight portfolios with their assigned weights below\n",
    "    max_sharpe_df = pd.DataFrame({'Asset_classes': max_sharpe_tickers, 'Weights': max_sharpe_weights})\n",
    "    max_sharpe_df = max_sharpe_df.sort_values('Weights', ascending=False)\n",
    "    max_sharpe_df['Weights'] = (max_sharpe_df['Weights'] * 100).round(2).astype(str) + '%'\n",
    "\n",
    "    min_var_df = pd.DataFrame({'Asset_classes': min_var_tickers, 'Weights': min_var_weights})\n",
    "    min_var_df = min_var_df.sort_values('Weights', ascending=False)\n",
    "    min_var_df['Weights'] = (min_var_df['Weights'] * 100).round(2).astype(str) + '%'\n",
    "\n",
    "    closest_std_df = pd.DataFrame({'Asset_classes': closest_std_tickers, 'Weights': closest_std_weights})\n",
    "    closest_std_df = closest_std_df.sort_values('Weights', ascending=False)\n",
    "    closest_std_df['Weights'] = (closest_std_df['Weights'] * 100).round(2).astype(str) + '%'\n",
    "    closest_std_return = np.round(mean_variance_pairs[closest_index][0] * 100,decimals=2)\n",
    "    closest_std_risk = np.round(mean_variance_pairs[closest_index][1]**0.5 * 100,decimals=2)\n",
    "\n",
    "    # Transform retail portfolio ret and std. for plot\n",
    "    retail_return = np.round(retail_return * 100,decimals=2)\n",
    "    retail_std = np.round(retail_std * 100,decimals=2)\n",
    "\n",
    "    retail_asset_allocation_df = retail_asset_allocation.copy()\n",
    "    retail_asset_allocation_df = retail_asset_allocation_df.sort_values('Allocation', ascending=False)\n",
    "    retail_asset_allocation_df['Allocation'] = (retail_asset_allocation['Allocation'] * 100).round(2).astype(str) + '%'\n",
    "    retail_asset_allocation_df.reset_index(inplace=True)\n",
    "    retail_asset_allocation_df.rename(columns={'Asset Class': 'Asset_classes', 'Allocation': 'Weights'},inplace = True)\n",
    "    retail_asset_allocation_df['Asset_classes'] = retail_asset_allocation_df['Asset_classes'].str.lower()\n",
    "\n",
    "    # remove index of max_sharpe_df and min_var_df\n",
    "    max_sharpe_df = max_sharpe_df.reset_index(drop=True)\n",
    "    min_var_df = min_var_df.reset_index(drop=True)\n",
    "    closest_std_df = closest_std_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # define CSS styles for the table\n",
    "    styles = [\n",
    "        dict(selector=\"th\", props=[(\"text-align\", \"center\"), (\"font-family\", \"Poppins\")]),\n",
    "        dict(selector=\"td\", props=[(\"text-align\", \"center\"), (\"font-family\", \"Poppins\")]),\n",
    "    ]\n",
    "\n",
    "    # create HTML code for the dataframes with titles\n",
    "    max_sharpe_html = f\"<div style='display: inline-block; vertical-align: top; margin-right: 20px;'><h3 style='font-family: Poppins; font-size: 130%;'>Max Sharpe</h3>Return: {max_sharpe_return}%, Std.: {max_sharpe_risk}% <br><br>{max_sharpe_df.style.set_table_styles(styles).to_html(index=False)}</div>\"\n",
    "    min_var_html = f\"<div style='display: inline-block; vertical-align: top; margin-right: 20px;'><h3 style='font-family: Poppins; font-size: 130%;'>Min Variance</h3>Return: {min_var_return}%, Std.: {min_var_risk}% <br><br>{min_var_df.style.set_table_styles(styles).to_html(index=False)}</div>\"\n",
    "    closest_std_html = f\"<div style='display: inline-block; vertical-align: top; margin-right: 20px;'><h3 style='font-family: Poppins; font-size: 130%;'>Risk Matching Portfolio</h3>Return: {closest_std_return}%, Std.: {closest_std_risk}% <br><br>{closest_std_df.style.set_table_styles(styles).to_html(index=False)}</div>\"\n",
    "    retail_html = f\"<div style='display: inline-block; vertical-align: top;'><h3 style='font-family: Poppins; font-size: 130%;'>Retail Portfolio</h3>Return: {retail_return}%, Std.: {retail_std}% <br><br>{retail_asset_allocation_df.style.set_table_styles(styles).to_html(index=False)}</div>\"\n",
    "\n",
    "    # Return the outputs\n",
    "    return fig,max_sharpe_html,min_var_html,closest_std_html,retail_html\n",
    "\n",
    "\n",
    "# function to load, transform and create data set\n",
    "def data_loader (time_start,time_end,retail_asset_classes):\n",
    "\n",
    "\n",
    "    #######   ##                                                                                                                 \n",
    "    #######    ##                                                                                                                \n",
    "        ##     ##                #     #     #  #######  #######  #######  #######           ######   #######  #######  ####### \n",
    "        ####     ##                #     ##   ##  #     #  #     #  #     #     #              #     #  #     #     #     #     # \n",
    "        ##     ##                #     # # # #  #######  #     #  #######     #              #     #  #######     #     ####### \n",
    "    #######    ##                 #     #  #  #  #        #     #  #    #      #              #     #  #     #     #     #     # \n",
    "    #######   ##                  #     #     #  #        #######  #    ##     #              ######   #     #     #     #     # \n",
    "\n",
    "    \n",
    "    path = os.path.abspath(\"../Data\")\n",
    "    \n",
    "    # Import quarterly index data from Preqin\n",
    "    preqin_quarter_file = path + '/preqin_export_Private Capital_Quarterly_Index_Chart_2023_5_12.csv'\n",
    "    preqin_data_quarter = pd.read_csv(preqin_quarter_file,delimiter=';', decimal=',')\n",
    "\n",
    "    # Import Bloomberg data\n",
    "    bloomberg_file = path + '/Bloomberg_selected_data.csv'\n",
    "    bloomberg_data = pd.read_csv(bloomberg_file,delimiter=';', decimal=',')\n",
    "\n",
    "    # Import DAX from Yahoo Finance\n",
    "    dax_file = path + '/GDAXI.csv'\n",
    "    dax_data = pd.read_csv(dax_file,delimiter=',', decimal='.')\n",
    "    \n",
    "    # Import SDAX\n",
    "    sdax_file = path + '/SDAX_Historical_Data.csv'\n",
    "    sdax = pd.read_csv(sdax_file,delimiter=',', decimal='.')\n",
    "\n",
    "    # Import Fixed_term_and_savings_deposit returns from Deutsche Bundesbank\n",
    "    savings_file = path + '/Fixed_Term_and_Savings_Deposit_Deutsche_Bundesbank.csv'\n",
    "    savings_data = pd.read_csv(savings_file,delimiter=';', decimal=',')\n",
    "\n",
    "    # Import Investment fund data from Rifinitiv\n",
    "    Investment_fund_file = path + '/German_Investment_funds.csv'\n",
    "    Investment_fund_data = pd.read_csv(Investment_fund_file,delimiter=';', decimal=',')\n",
    "\n",
    "\n",
    "    # Create a dictionary with the asset allocation (incl. similar risk/return proxies) of German Private Housholds in 2022\n",
    "    houshold_data = {\n",
    "    'Asset Class': ['Listed Foreign Public Equity','Other Equity Instruments','State Bonds','Corporate Bonds','Listed Domestic Public Equity','Fixed Term and Savings Deposit','Public Investment Funds','Cash'],\n",
    "    'Allocation': ['5%', '8.4%', '0.73%', '1.46%', '5.9%', '17.1%', '18.6%','42.8%']\n",
    "    }\n",
    "\n",
    "    # Create the dataframe\n",
    "    retail_asset_allocation = pd.DataFrame(houshold_data)\n",
    "\n",
    "\n",
    "    ##   ##   ##                                                                                                                                   \n",
    "    ##   ##    ##                                                                                                                                  \n",
    "    ##   ##     ##             ######   #######  #######  #######           #######  #        #######  #######  #     #     #     #     #  ####### \n",
    "    # #####     ##             #     #  #     #     #     #     #           #        #        #        #     #  ##    #     #     ##    #  #       \n",
    "        ##     ##             #     #  #######     #     #######           #        #        ####     #######  # ### #     #     # ### #  #  #### \n",
    "        ##    ##              #     #  #     #     #     #     #           #        #        #        #     #  #    ##     #     #    ##  #     # \n",
    "        ##   ##               ######   #     #     #     #     #           #######  #######  #######  #     #  #     #     #     #     #  #######\n",
    "\n",
    "\n",
    "    # PREQIN QUARTERLY DATA\n",
    "    # drop the first row\n",
    "    preqin_data_quarter = preqin_data_quarter.drop(0)\n",
    "\n",
    "    # set the new column titles\n",
    "    preqin_data_quarter.columns = preqin_data_quarter.iloc[0]\n",
    "    preqin_data_quarter = preqin_data_quarter.drop(1)\n",
    "\n",
    "    # reset the index\n",
    "    preqin_data_quarter = preqin_data_quarter.reset_index(drop=True)\n",
    "\n",
    "    preqin_data_quarter['DATE'] = pd.to_datetime(preqin_data_quarter['DATE'], format='%b-%y') + pd.offsets.MonthEnd(0)\n",
    "    preqin_data_quarter['DATE'] = preqin_data_quarter['DATE'].dt.strftime('%d.%m.%Y')\n",
    "\n",
    "    # set the date column as the index\n",
    "    preqin_data_quarter = preqin_data_quarter.set_index('DATE')\n",
    "\n",
    "    # convert the index to a DatetimeIndex\n",
    "    preqin_data_quarter.index = pd.to_datetime(preqin_data_quarter.index)\n",
    "\n",
    "    # replace commas with dots in all columns\n",
    "    preqin_data_quarter = preqin_data_quarter.replace(',', '.', regex=True)\n",
    "\n",
    "    # convert the values to numbers\n",
    "    preqin_data_quarter = preqin_data_quarter.apply(pd.to_numeric)\n",
    "\n",
    "    # calculate the quarterly returns\n",
    "    preqin_quarterly_returns = preqin_data_quarter.resample('Q').last().pct_change()\n",
    "\n",
    "    # drop the first row of the quarterly_returns DataFrame\n",
    "    preqin_quarterly_returns = preqin_quarterly_returns.drop(preqin_quarterly_returns.index[0])\n",
    "\n",
    "    # Filter rows based on year condition\n",
    "    # Convert start and end to pd.datetime format\n",
    "    preqin_start = pd.to_datetime(str(time_start))\n",
    "    preqin_end = pd.to_datetime(str(time_end+1))\n",
    "\n",
    "    # Create a boolean mask based on the condition\n",
    "    mask = (preqin_quarterly_returns.index >= preqin_start) & (preqin_quarterly_returns.index <= preqin_end)\n",
    "\n",
    "    # Filter the DataFrame using the boolean mask\n",
    "    preqin_quarterly_returns = preqin_quarterly_returns[mask]\n",
    "\n",
    "\n",
    "    # Convert the \"Date\" column to datetime\n",
    "    bloomberg_data['Date'] = pd.to_datetime(bloomberg_data['Date'], format='%d.%m.%Y')\n",
    "\n",
    "    # Set the \"Date\" column as the index\n",
    "    bloomberg_data.set_index('Date', inplace=True)\n",
    "\n",
    "    # Convert the index to a DatetimeIndex\n",
    "    bloomberg_data.index = pd.to_datetime(bloomberg_data.index)\n",
    "\n",
    "    # Filter rows based on year condition\n",
    "    # Convert start and end to pd.datetime format\n",
    "    x = pd.to_datetime(str(time_start))\n",
    "    y = pd.to_datetime(str(time_end+1))\n",
    "\n",
    "    # Create a boolean mask based on the condition\n",
    "    mask = (bloomberg_data.index >= x) & (bloomberg_data.index <= y)\n",
    "\n",
    "    bloomberg_data = bloomberg_data[mask]\n",
    "\n",
    "    bloomberg_data.drop(bloomberg_data.columns[[0, 2]], axis=1, inplace=True)\n",
    "\n",
    "    # Rename the columns\n",
    "    bloomberg_data.rename(columns={\n",
    "        '% Change': 'Bloomberg Euro Aggregate Corporate Total Return Index EU',\n",
    "        '% Change.1': 'Bloomberg Euro Aggregate Treasury Germany Total Return Index'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Divide all columns by 100\n",
    "    bloomberg_data = bloomberg_data / 100\n",
    "\n",
    "    # Invert rows\n",
    "    bloomberg_data = bloomberg_data.iloc[::-1]\n",
    "    bloomberg_returns = bloomberg_data.copy()\n",
    "\n",
    "\n",
    "    # DAX DATA\n",
    "    # First, we need to convert the \"Date\" column to a datetime type\n",
    "    dax_data['Date'] = pd.to_datetime(dax_data['Date'])\n",
    "\n",
    "    # Set the \"Date\" column as the index of the DataFrame\n",
    "    dax_data.set_index('Date', inplace=True)\n",
    "\n",
    "    # Create an empty DataFrame to store the monthly returns\n",
    "    dax_monthly_rets = pd.DataFrame(columns=['Year', 'DAX'])\n",
    "\n",
    "    # Calculate and populate the monthly returns\n",
    "    months = dax_data.resample('M').agg({'Close': ['last']})\n",
    "    # Shift the 'Close' column one row to get the previous month's 'Close' price\n",
    "    months['Previous_Close'] = months['Close'].shift(1)\n",
    "\n",
    "    # Calculate the monthly return as the percentage change in 'Close' prices\n",
    "    months['DAX'] = (months['Close','last'] / months['Previous_Close'] - 1)\n",
    "    months.drop(columns=['Previous_Close','Close'], inplace=True)\n",
    "\n",
    "    dax_monthly_rets = months.copy()\n",
    "\n",
    "    # Filter rows based on year condition\n",
    "    # Convert start and end to pd.datetime format\n",
    "    x = pd.to_datetime(str(time_start))\n",
    "    y = pd.to_datetime(str(time_end+1))\n",
    "\n",
    "    # Create a boolean mask based on the condition\n",
    "    mask = (dax_monthly_rets.index >= x) & (dax_monthly_rets.index <= y)\n",
    "\n",
    "    # Filter the DataFrame using the boolean mask\n",
    "    dax_monthly_rets = dax_monthly_rets[mask]\n",
    "\n",
    "    # Remove the second heading level of the multi-level index\n",
    "    dax_monthly_rets.columns = dax_monthly_rets.columns.droplevel(1)\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "    # SDAX DATA\n",
    "    # Step 1: Select the first two columns\n",
    "    sdax = sdax[['Date', 'Price']]\n",
    "\n",
    "    # Step 2: Parse the Date column to datetime\n",
    "    sdax['Date'] = pd.to_datetime(sdax['Date'], format='%m/%d/%Y')\n",
    "\n",
    "    # Step 3: Set the Date column as the index\n",
    "    sdax.set_index('Date', inplace=True)\n",
    "\n",
    "    # Step 4: Remove commas and convert Price column to numeric\n",
    "    sdax['SDAX'] = pd.to_numeric(sdax['Price'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "    # Drop the original 'Price' column\n",
    "    sdax.drop(columns=['Price'], inplace=True)\n",
    "\n",
    "    # Step 5: Calculate monthly returns\n",
    "    sdax_monthly_returns = sdax['SDAX'].resample('M').first().pct_change()\n",
    "\n",
    "    # Adjust the monthly returns to represent the return for the current month\n",
    "    sdax_monthly_returns.index = sdax_monthly_returns.index + pd.DateOffset(months=-1)\n",
    "\n",
    "    # Step 6: Filter rows based on the year condition\n",
    "    # Convert start and end to pd.datetime format\n",
    "    x = pd.to_datetime(str(time_start), format='%Y')\n",
    "    y = pd.to_datetime(str(time_end+1), format='%Y')\n",
    "\n",
    "    # Create a boolean mask based on the condition\n",
    "    temp_mask = (sdax_monthly_returns.index >= x) & (sdax_monthly_returns.index <= y)\n",
    "\n",
    "    # Filter the DataFrame using the boolean mask\n",
    "    sdax_monthly_rets = sdax_monthly_returns[temp_mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # SAVINGS AND DEPOSIT DATA\n",
    "    # Convert Year and Month columns to datetime format and add last day of the month\n",
    "    savings_data['Date'] = pd.to_datetime(savings_data[['Year', 'Month']].assign(day=1)).dt.to_period('M').dt.to_timestamp('M') + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    # Calculate savings_returns based on the provided formula\n",
    "    savings_data['savings_returns'] = (savings_data['Return, % p.a.'] / 12) * 0.01\n",
    "\n",
    "    # Select only the Date and savings_returns columns for the final DataFrame\n",
    "    savings_monthly = savings_data[['Date', 'savings_returns']]\n",
    "\n",
    "    # Set the 'Year' column as the index\n",
    "    savings_monthly = savings_monthly.set_index('Date')\n",
    "\n",
    "    # Create a boolean mask based on the condition\n",
    "    mask = (savings_monthly.index >= x) & (savings_monthly.index <= y)\n",
    "    savings_monthly = savings_monthly[mask]\n",
    "\n",
    "\n",
    "    # Investment Fund\n",
    "    # Delete the first row\n",
    "    Investment_fund_data = Investment_fund_data.iloc[1:]\n",
    "\n",
    "    # Typecast the first column to pd.datetime and name it 'date'\n",
    "    Investment_fund_data['Date'] = pd.to_datetime(Investment_fund_data.iloc[:, 0], format='%d-%b-%Y')\n",
    "\n",
    "    # Set 'date' column as the index\n",
    "    Investment_fund_data.set_index('Date', inplace=True)\n",
    "\n",
    "    # Delete the first column where the old date format is storedâ€˜\n",
    "    Investment_fund_data = Investment_fund_data.iloc[:, 1:]\n",
    "\n",
    "    # Create a new column named 'Investment_Funds' with average return per row\n",
    "    Investment_fund_data['Investment_Funds'] = Investment_fund_data.mean(axis=1)\n",
    "\n",
    "    investment_fund_return = pd.DataFrame(Investment_fund_data['Investment_Funds'])\n",
    "\n",
    "    investment_fund_return = investment_fund_return.drop(investment_fund_return.index[0])\n",
    "    investment_fund_return = investment_fund_return.drop(investment_fund_return.index[0])\n",
    "\n",
    "    # Filter rows based on time condition\n",
    "    investment_fund_return = investment_fund_return.loc[(investment_fund_return.index >= x)& (investment_fund_return.index <= y)]\n",
    "\n",
    "\n",
    "\n",
    "    #######   ##                                                                                                                                                                       \n",
    "    #######    ##                                                                                                                                                                      \n",
    "    #           ##             ######   #######  #######  #######           #######  #######  #######           #######  #######  #######  #######  #######     #     #######  #     # \n",
    "    #######     ##             #     #  #     #     #     #     #           #        #           #              #        #     #  #        #     #     #        #     #     #  ##    # \n",
    "        ##     ##             #     #  #######     #     #######           #######  ####        #              #        #######  ####     #######     #        #     #     #  # ### # \n",
    "    #######    ##              #     #  #     #     #     #     #                 #  #           #              #        #    #   #        #     #     #        #     #     #  #    ## \n",
    "    #######   ##               ######   #     #     #     #     #           #######  #######     #              #######  #    ##  #######  #     #     #        #     #######  #     # \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## SET Creation ##\n",
    "\n",
    "    ## Monthly return set##\n",
    "    dax_monthly_rets = dax_monthly_rets.reset_index()\n",
    "\n",
    "    # Reset index and drop \"Date\" column for sdax\n",
    "    sdax_monthly_rets = sdax_monthly_rets.reset_index().drop(columns=['Date'])\n",
    "\n",
    "    # Reset index and drop \"Date\" column for investment_fund_return\n",
    "    investment_fund_return_reset = investment_fund_return.reset_index().drop(columns=['Date'])\n",
    "\n",
    "    # Reset index and drop \"Date\" column for bloomberg_returns\n",
    "    bloomberg_returns_reset = bloomberg_returns.reset_index().drop(columns=['Date'])\n",
    "\n",
    "    # Reset index and drop \"Date\" column for savings_returns\n",
    "    savings_monthly_reset = savings_monthly.reset_index().drop(columns=['Date'])\n",
    "\n",
    "    # Concatenate the columns of the three dataframes\n",
    "    monthly_returns = pd.concat([dax_monthly_rets, sdax_monthly_rets, investment_fund_return_reset, bloomberg_returns_reset,savings_monthly_reset], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    ## Quarterly return set##\n",
    "\n",
    "    # Step 2: Set the 'Date' column as the index\n",
    "    monthly_returns.set_index('Date', inplace=True)\n",
    "\n",
    "    combined_quarterly = monthly_returns.groupby(pd.Grouper(freq='Q')).apply(lambda x: (1 + x).prod() - 1)\n",
    "\n",
    "    # Preqin-----------\n",
    "    # Reset index and drop \"Date\" column for bloomberg_returns\n",
    "    preqin_quarterly_returns_reset = preqin_quarterly_returns.reset_index().drop(columns=['DATE'])\n",
    "\n",
    "    # Concatenate the columns of the three dataframes\n",
    "\n",
    "    combined_quarterly_reset = combined_quarterly.reset_index()\n",
    "    quarterly_returns = pd.concat([combined_quarterly_reset, preqin_quarterly_returns_reset], axis=1)\n",
    "\n",
    "    # Add CASH as a 0-constant\n",
    "    quarterly_returns['CASH'] = 0.00\n",
    "\n",
    "\n",
    "    # Define a dictionary to map the old column names to the new column names\n",
    "    column_mapping = {\n",
    "    'S&P 500 TOTAL RETURN': 'Listed Foreign Public Equity',\n",
    "    'SDAX': 'Other Equity Instruments',\n",
    "    'Bloomberg Euro Aggregate Treasury Germany Total Return Index': 'State Bonds',\n",
    "    'Bloomberg Euro Aggregate Corporate Total Return Index EU': 'Corporate Bonds',\n",
    "    'DAX': 'Listed Domestic Public Equity',\n",
    "    'savings_returns': 'Fixed Term and Savings Deposit',\n",
    "    'Investment_Funds': 'Public Investment Funds',\n",
    "    'CASH': 'Cash'\n",
    "    }\n",
    "\n",
    "    # Rename the columns using the column_mapping dictionary\n",
    "    quarterly_returns = quarterly_returns.rename(columns=column_mapping)\n",
    "\n",
    "\n",
    "    ## Annual return set ##\n",
    "\n",
    "\n",
    "    # Create annual return set by grouping by year and summing the quarterly returns to get annual returns, taking into account the compounding effect within each year.\n",
    "    # Set the 'Date' column as the index\n",
    "    quarterly_returns.set_index('Date', inplace=True)\n",
    "\n",
    "    annual_returns = quarterly_returns.groupby(pd.Grouper(freq='Y')).apply(lambda x: (1 + x).prod() - 1)\n",
    "\n",
    "    # Convert index to datetime format and extract year\n",
    "    annual_returns.index = pd.to_datetime(annual_returns.index).year\n",
    "\n",
    "    # Rename the index to 'Year'\n",
    "    annual_returns.index.name = 'Year'\n",
    "\n",
    "\n",
    "    # GERMAN RETIAL INVESTOR PORTFOLIO CREATION\n",
    "\n",
    "\n",
    "    # Select the desired columns from the dataframe\n",
    "    retail_annual_returns = annual_returns[retail_asset_classes]\n",
    "\n",
    "    # Transform the Allocation column to floats\n",
    "    retail_asset_allocation['Allocation'] = retail_asset_allocation['Allocation'].str.rstrip('%').astype(float) / 100\n",
    "\n",
    "    # Set 'Asset Class' as the index\n",
    "    retail_asset_allocation.set_index('Asset Class', inplace=True)\n",
    "\n",
    "    # Calculate weighted returns\n",
    "    weighted_returns = retail_annual_returns.mul(retail_asset_allocation['Allocation'], axis=1)\n",
    "\n",
    "    # Calculate the weighted average return per year\n",
    "    retail_annual_returns['RETURN'] = weighted_returns.sum(axis=1)\n",
    "\n",
    "    # Calculate standard deviation and mean return\n",
    "    retail_std = retail_annual_returns['RETURN'].std()\n",
    "    retail_return = retail_annual_returns['RETURN'].mean()\n",
    "\n",
    "    return annual_returns, quarterly_returns, retail_asset_allocation, retail_annual_returns, retail_return, retail_std\n",
    "\n",
    "#######   ##                                                                                                                                                                                                                    \n",
    "#######    ##                                                                                                                                                                                                                   \n",
    "##          ##             ######   #######  #######  #######  #######     #     #######  #######     #     #     #  #######           #######  #######  #######  #######     #     #######  #######     #     #######  ####### \n",
    "#######     ##             #     #  #        #        #        #     #     #     #     #     #        #     #     #  #                 #           #     #     #     #        #     #           #        #     #        #       \n",
    "##   ##     ##             #     #  ####     #######  #        #######     #     #######     #        #      #   #   ####              #######     #     #######     #        #     #######     #        #     #        ####### \n",
    "#######    ##              #     #  #              #  #        #    #      #     #           #        #       # #    #                       #     #     #     #     #        #           #     #        #     #              # \n",
    "#######   ##               ######   #######  #######  #######  #    ##     #     #           #        #        #     #######           #######     #     #     #     #        #     #######     #        #     #######  ####### \n",
    "\n",
    "# Load data set\n",
    "annual_returns, quarterly_returns, retail_asset_allocation, retail_annual_returns, retail_return, retail_std = data_loader(time_start,time_end,retail_asset_classes)\n",
    "\n",
    "# Define colors for the chart\n",
    "colors = ['#FFDC26', '#FF7F0E', '#2CA02C', '#D62728', '#9467BD', '#1F77B4', '#17becf', '#7F7F7F']\n",
    "\n",
    "# Plot the retail asset allocation chart\n",
    "fig = go.Figure(data=[go.Pie(labels=retail_asset_allocation.index, values=retail_asset_allocation['Allocation'], hole=0.4, marker=dict(colors=colors))])\n",
    "\n",
    "# Set the aspect ratio to make the plot square-sized\n",
    "fig.update_layout(\n",
    "    width=600,\n",
    "    height=600,\n",
    "    legend=dict(orientation='h', y=-0.2)\n",
    ")\n",
    "# Set the axis labels and plot title\n",
    "fig.update_layout(\n",
    "    title='Retail Allocation Plot'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Drop Return column\n",
    "retail_annual_returns.drop(columns=['RETURN'],inplace=True)\n",
    "\n",
    "# Convert the column names (x-axis labels) to lowercase for retail_annual_returns\n",
    "annual_returns.columns = annual_returns.columns.str.lower()\n",
    "quarterly_returns.columns = quarterly_returns.columns.str.lower()\n",
    "\n",
    "# Select asset classes\n",
    "active_classes = [element.lower() for element in active_classes]\n",
    "selected_returns = annual_returns[active_classes]\n",
    "selected_quarterly_returns = quarterly_returns[active_classes]\n",
    "\n",
    "# Calculate summary statistics for each asset class\n",
    "stats = pd.DataFrame(index=['mean', 'median', 'std', 'skewness', 'kurtosis'])\n",
    "for col in selected_quarterly_returns.columns:\n",
    "    selected_quarterly_returns[col] = selected_quarterly_returns[col].astype(float)\n",
    "    selected_returns[col] = selected_returns[col].astype(float)\n",
    "    mean = selected_returns[col].mean()\n",
    "    median = selected_returns[col].median()\n",
    "    std = selected_quarterly_returns[col].std() * np.sqrt(4)\n",
    "    skewness_value = skew(selected_quarterly_returns[col])\n",
    "    kurtosis_value = kurtosis(selected_quarterly_returns[col])\n",
    "    stats[col] = [mean, median, std, skewness_value, kurtosis_value]\n",
    "\n",
    "# Convert the column names (x-axis labels) to lowercase\n",
    "stats.columns = stats.columns.str.lower()\n",
    "\n",
    "# How many assests in the portfolio\n",
    "n_assets = selected_returns.shape[1]\n",
    "\n",
    "# transpose the table\n",
    "stats_selected = stats.T\n",
    "# Rename Index to asset_class\n",
    "stats_selected.rename_axis('asset_class',inplace=True)\n",
    "mus = (stats_selected['mean'])\n",
    "\n",
    "# Covariance matrix of the asset classes based on annualized quarterly returns\n",
    "cov = selected_quarterly_returns.cov() * 4\n",
    "\n",
    "# Create a scatter plot for return/risk analysis\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=stats_selected['std'],\n",
    "    y=stats_selected['mean'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        color='blue',\n",
    "        symbol='circle'\n",
    "    )\n",
    "))\n",
    "\n",
    "# Set the aspect ratio to make the plot square-sized\n",
    "fig.update_layout(\n",
    "    width=600,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Set the axis labels and plot title\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title='Standard Deviation'),\n",
    "    yaxis=dict(title='Mean'),\n",
    "    title='Risk-Return Plot'\n",
    ")\n",
    "\n",
    "# Add annotations for each asset class\n",
    "annotations = [\n",
    "    dict(\n",
    "        x=x_val,\n",
    "        y=y_val,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        text=asset,\n",
    "        showarrow=True,\n",
    "        arrowhead=7,\n",
    "        ax=0,\n",
    "        ay=-40\n",
    "    )\n",
    "    for asset, x_val, y_val in zip(stats_selected.index, stats_selected['std'], stats_selected['mean'])\n",
    "]\n",
    "\n",
    "fig.update_layout(\n",
    "    annotations=annotations\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Create the line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for column in selected_returns.columns[1:]:\n",
    "    fig.add_trace(go.Scatter(x=selected_returns.index, y=selected_returns[column], mode='lines', name=column,))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title='Returns Over Time',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Return',\n",
    "    legend_title='Asset Class',\n",
    "    hovermode='x',\n",
    "    height=600,\n",
    "    xaxis=dict(\n",
    "        type='date',\n",
    "        tickformat='%Y',\n",
    "        dtick='M12'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Return estimators\n",
    "\n",
    "selected_means = selected_returns.mean()\n",
    "selected_medians = selected_returns.median()\n",
    "\n",
    "# Calculate the annual geometric mean for each asset\n",
    "geometric_means = (selected_returns + 1).prod()**(1 / len(selected_returns)) - 1\n",
    "\n",
    "# Bayes-Stein (shrinkage)\n",
    "# drop cash as 0 const otherwise the matrix cannot be inverted\n",
    "# Find the index number of the column 'cash'\n",
    "index_cash = selected_returns.columns.get_loc('cash')\n",
    "selected_returns_wo_cash = selected_returns.drop(columns='cash')\n",
    "selected_bayes_stein_returns = bayes_stein_returns(selected_returns_wo_cash)\n",
    "# Create a new Series with the \"cash\" asset class and its corresponding return value\n",
    "cash_series = pd.Series([0.0], index=[\"cash\"])\n",
    "# Concatenate the new_series with the original selected_bayes_stein_returns series\n",
    "selected_bayes_stein_returns = pd.concat([selected_bayes_stein_returns.iloc[:index_cash], cash_series, selected_bayes_stein_returns.iloc[index_cash:]])\n",
    "\n",
    "\n",
    "# Risk estimators\n",
    "\n",
    "selected_skewness = selected_returns.skew()\n",
    "selected_kurtosis = selected_returns.kurtosis()\n",
    "selected_std_dev = selected_quarterly_returns.std() * np.sqrt(4)\n",
    "selected_cvar = selected_returns.apply(calculate_cvar, alpha=0.9)\n",
    "\n",
    "\n",
    "# Normality Tests\n",
    "# Perform Jarque-Bera test\n",
    "selected_jb = selected_returns.apply(lambda x: jarque_bera(x)[0])\n",
    "selected_jb_p = selected_returns.apply(lambda x: jarque_bera(x)[1])\n",
    "# Perform Shapiro-Wilk test\n",
    "selected_sw = selected_returns.apply(lambda x: shapiro(x)[0])\n",
    "selected_sw_p = selected_returns.apply(lambda x: shapiro(x)[1])\n",
    "# Perform Anderson-Darling test\n",
    "selected_ad = selected_returns.apply(lambda x: anderson(x, dist='norm')[0])\n",
    "# Create an empty dictionary to store the significance levels\n",
    "significance_levels = {}\n",
    "\n",
    "# Iterate over each column in the DataFrame\n",
    "for column in selected_returns.columns:\n",
    "    # Perform the Anderson-Darling normality test on the column\n",
    "    result = anderson(selected_returns[column])\n",
    "    \n",
    "    # Extract the critical values and significance levels\n",
    "    critical_values = result.critical_values\n",
    "    significance = result.significance_level\n",
    "    \n",
    "    # Find the index at which the null hypothesis can be rejected\n",
    "    rejection_index = next((i for i, cv in enumerate(critical_values) if result.statistic > cv), None)\n",
    "    \n",
    "    # If rejection index is found, find the corresponding significance level\n",
    "    if rejection_index is not None:\n",
    "        rejection_level = significance[rejection_index]\n",
    "    else:\n",
    "        rejection_level = None\n",
    "    \n",
    "    # Store the significance level in the dictionary\n",
    "    significance_levels[column] = rejection_level\n",
    "series_modified =  pd.Series(significance_levels).fillna(-1).astype(int) / 100\n",
    "series_modified[series_modified == -0.01] = np.nan\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "comparison_df = pd.DataFrame({\n",
    "    ('Return','Mean'): selected_means,\n",
    "    ('Return','Median'): selected_medians,\n",
    "    ('Return','Geometric Mean'): geometric_means,\n",
    "    ('Return','Bayes Stein'): selected_bayes_stein_returns,\n",
    "    ('Risk','Standard Dev.'): selected_std_dev,\n",
    "    ('Risk','Skewness'): selected_skewness,\n",
    "    ('Risk','Kurtosis'): selected_kurtosis,\n",
    "    ('Risk','CVaR'): selected_cvar,\n",
    "    ('Normality Tests', 'Jarque-Bera') : selected_jb,\n",
    "    ('Normality Tests', 'p-value') : selected_jb_p,\n",
    "    ('Normality Tests', 'Shapiro-Wilk') : selected_sw,\n",
    "    ('Normality Tests', 'p-value ') : selected_sw_p,\n",
    "    ('Normality Tests', 'Anderson-Darling') : selected_ad,\n",
    "    ('Normality Tests', 'sig.') : series_modified\n",
    "})\n",
    "\n",
    "comparison_df_save = comparison_df.copy()\n",
    "\n",
    "# Sort the DataFrame by geometric mean in descending order\n",
    "comparison_df.sort_values(('Return','Mean'), ascending=False, inplace= True)\n",
    "\n",
    "# Apply color scale to each column in ascending order\n",
    "comparison_df = comparison_df.style.background_gradient(axis=0)\n",
    "\n",
    "comparison_df = comparison_df.set_table_styles([\n",
    "    {'selector': 'th.col_heading.level0', 'props': [('text-align', 'center')]}\n",
    "])\n",
    "\n",
    "\n",
    "# Display the styled DataFrame\n",
    "display(comparison_df)\n",
    "\n",
    "\n",
    "#######   ##                                                                                                                                                                                                           \n",
    "#######    ##                                                                                                                                                                                                          \n",
    "     ##     ##             #######  #######  #######  #######  #######  #######  #           #     #######           #######     #     #     #  #     #  #        #######  #######     #     #######  #     #  ####### \n",
    "     ##     ##             #     #  #     #  #     #     #     #        #     #  #           #     #     #           #           #     ##   ##  #     #  #        #     #     #        #     #     #  ##    #  #       \n",
    "     ##     ##             #######  #     #  #######     #     ####     #     #  #           #     #     #           #######     #     # # # #  #     #  #        #######     #        #     #     #  # ### #  ####### \n",
    "     ##    ##              #        #     #  #    #      #     #        #     #  #           #     #     #                 #     #     #  #  #  #     #  #        #     #     #        #     #     #  #    ##        # \n",
    "     ##   ##               #        #######  #    ##     #     #        #######  #######     #     #######           #######     #     #     #  #######  #######  #     #     #        #     #######  #     #  ####### \n",
    "\n",
    "\n",
    "# Find the index of 'cash' asset\n",
    "cash_index = list(selected_returns.columns).index('cash')\n",
    "\n",
    "\n",
    "# 1) Monte Carlo Simulation - w/o weight restrictions\n",
    "\n",
    "# Create random portfolio weights and indexes\n",
    "mean_variance_pairs_un = []\n",
    "weights_list_un=[]\n",
    "tickers_list_un=[]\n",
    "\n",
    "for i in tqdm(range(n_unrestricted)):\n",
    "    next_i = False\n",
    "    while True:\n",
    "\n",
    "        assets = list(selected_returns.columns)\n",
    "        #- Choose weights randomly ensuring they sum to one\n",
    "        weights = np.random.rand(n_assets-1)\n",
    "        weights = weights/sum(weights)\n",
    "        \n",
    "        # Adjust weights for non-cash financial assets\n",
    "        weights = weights * (1-cash_level)\n",
    "\n",
    "        # Create a new array with an extra slot for the new element\n",
    "        new_array = np.zeros(len(weights) + 1)\n",
    "\n",
    "        # Copy elements before the insertion index to the new array\n",
    "        new_array[:cash_index] = weights[:cash_index]\n",
    "\n",
    "        # Insert the element at the desired index\n",
    "        new_array[cash_index] = cash_level\n",
    "\n",
    "        # Copy elements after the insertion index one spot further out\n",
    "        new_array[cash_index + 1:] = weights[cash_index:]\n",
    "\n",
    "        weights = new_array.copy()\n",
    "        \n",
    "\n",
    "        #-- Loop over asset pairs and compute portfolio return and variance\n",
    "        portfolio_E_Variance = 0\n",
    "        portfolio_E_Return = 0\n",
    "        for i in range(len(assets)):\n",
    "            portfolio_E_Return += weights[i] * mus.loc[assets[i]]\n",
    "            for j in range(len(assets)):\n",
    "                portfolio_E_Variance += weights[i] * weights[j] * cov.loc[assets[i], assets[j]]\n",
    "\n",
    "        #-- Skip over dominated portfolios\n",
    "        for R,V in mean_variance_pairs_un:\n",
    "            if (R > portfolio_E_Return) & (V < portfolio_E_Variance):\n",
    "                next_i = True\n",
    "                break\n",
    "        if next_i:\n",
    "            break\n",
    "\n",
    "        #-- Add the mean/variance pairs to a list for plotting\n",
    "        mean_variance_pairs_un.append([portfolio_E_Return, portfolio_E_Variance])\n",
    "        weights_list_un.append(weights)\n",
    "        tickers_list_un.append(assets)\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# 2) Monte Carlo Simulation - with weight restrictions\n",
    "\n",
    "# Create random portfolio weights and indexes\n",
    "mean_variance_pairs_re = []\n",
    "weights_list_re=[]\n",
    "tickers_list_re=[]\n",
    "\n",
    "for i in tqdm(range(n_restricted)):\n",
    "    next_i = False\n",
    "    while True:\n",
    "\n",
    "        #- Choose assets randomly without replacement\n",
    "        assets = list(selected_returns.columns)\n",
    "\n",
    "\n",
    "        #- Choose weights randomly ensuring that they don't go above threshold\n",
    "        weights = np.random.rand(n_assets-1)\n",
    "        weights = weights/sum(weights)\n",
    "        while np.any(weights > max_weight):\n",
    "            weights = np.random.rand(n_assets-1)\n",
    "            weights = weights/sum(weights)\n",
    "\n",
    "        # Adjust weights for non-cash financial assets\n",
    "        weights = weights * (1-cash_level)\n",
    "\n",
    "        # Create a new array with an extra slot for the new element\n",
    "        new_array = np.zeros(len(weights) + 1)\n",
    "\n",
    "        # Copy elements before the insertion index to the new array\n",
    "        new_array[:cash_index] = weights[:cash_index]\n",
    "\n",
    "        # Insert the element at the desired index\n",
    "        new_array[cash_index] = cash_level\n",
    "\n",
    "        # Copy elements after the insertion index one spot further out\n",
    "        new_array[cash_index + 1:] = weights[cash_index:]\n",
    "\n",
    "        weights = new_array.copy()\n",
    "\n",
    "        #-- Loop over asset pairs and compute portfolio return and variance\n",
    "        portfolio_E_Variance = 0\n",
    "        portfolio_E_Return = 0\n",
    "        for i in range(len(assets)):\n",
    "            portfolio_E_Return += weights[i] * mus.loc[assets[i]]\n",
    "            for j in range(len(assets)):\n",
    "                portfolio_E_Variance += weights[i] * weights[j] * cov.loc[assets[i], assets[j]]\n",
    "\n",
    "        #-- Skip over dominated portfolios\n",
    "        for R,V in mean_variance_pairs_re:\n",
    "            if (R > portfolio_E_Return) & (V < portfolio_E_Variance):\n",
    "                next_i = True\n",
    "                break\n",
    "        if next_i:\n",
    "            break\n",
    "\n",
    "        #-- Add the mean/variance pairs to a list for plotting\n",
    "        mean_variance_pairs_re.append([portfolio_E_Return, portfolio_E_Variance])\n",
    "        weights_list_re.append(weights)\n",
    "        tickers_list_re.append(assets)\n",
    "\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "# Plot Portfolio Optimization with EF, and allocations\n",
    "\n",
    "# First set of input parameters\n",
    "title_name_un = 'Efficient Frontier of Unrestricted Portfolio'\n",
    "fig1, max_sharpe_html1, min_var_html1, closest_std_html1, retail_html1 = plot_ef(mean_variance_pairs_un, tickers_list_un, weights_list_un, risk_free_rate,retail_return,retail_std,title_name_un)\n",
    "\n",
    "\n",
    "# Second set of input parameters\n",
    "title_name_re = 'Efficient Frontier of Restricted Portfolio'\n",
    "fig2, max_sharpe_html2, min_var_html2, closest_std_html2, retail_html2 = plot_ef(mean_variance_pairs_re, tickers_list_re, weights_list_re, risk_free_rate,retail_return,retail_std,title_name_re)\n",
    "\n",
    "\n",
    "# Display the subplots\n",
    "fig1.show()\n",
    "# Display the combined HTML code\n",
    "display(HTML(max_sharpe_html1 + min_var_html1 + closest_std_html1 + retail_html1))\n",
    "\n",
    "fig2.show()\n",
    "# Display the combined HTML code\n",
    "display(HTML(max_sharpe_html2 + min_var_html2 + closest_std_html2 + retail_html2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Output as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_pairs_preqin_quarter_re = pd.DataFrame(mean_variance_pairs_re)\n",
    "cache_weights_preqin_quarter_re = pd.DataFrame(weights_list_re)\n",
    "cache_tickers_preqin_quarter_re = pd.DataFrame(tickers_list_re)\n",
    "\n",
    "cache_pairs_preqin_quarter_re.to_csv('Fixed_cash_No_alt_RE_8_pairs_4')\n",
    "cache_weights_preqin_quarter_re.to_csv('Fixed_cash_No_alt_RE_8_weights_4')\n",
    "cache_tickers_preqin_quarter_re.to_csv('Fixed_cash_No_alt_RE_8_tickers_4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
